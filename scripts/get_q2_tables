#!/usr/bin/env python3

import utils_noroot                as utnr
import matplotlib.pyplot           as plt
import os
import re
import zfit
import hist
import glob
import utils
import numpy
import pprint
import mplhep
import argparse
import ROOT
import logging
import read_selection as rs

from logzero      import logger    as log
from zutils.plot  import plot      as zfp
from rk.selection import selection as rksl
from zutils.utils import result_to_latex 
from fitter       import zfitter
from rk.mva       import mva_man
from rk.wgt_mgr   import wgt_mgr

#-------------------
class data:
    zfit.settings.changed_warnings.hesse_name = False

    log      = utnr.getLogger(__name__)
    cal_dir  = os.environ['CALDIR']
    dat_dir  = os.environ['DATDIR']
    cas_dir  = os.environ['CASDIR']
    mva_dir  = os.environ['MVADIR']
    qsq_dir  = os.environ['QSQSYS']

    l_trig   = ['ETOS', 'GTIS']
    l_year   = ['2011', '2012', '2015', '2016', '2017', '2018', 'r1', 'r2p1']
    l_brem   = ['0', '1', '2']
    l_sys    = ['nom', 'nspd']
    l_sam    = ['simulation', 'data', 'both']
    l_cali   = ['000', 'nom']

    dat_vers = 'v10.21p2'
    bdt_dir  = f'{mva_dir}/electron/bdt_v10.14.a0v2ss'
    b_mass   = 'B_const_mass_M[0]'
    j_mass   = 'Jpsi_M'
    nbins    = 60

    trig     = None 
    year     = None 
    brem     = None 
    plt_dir  = None 
    nentries = None
    d_sim_par= None
    skip_fit = None
    nevs_data= None
    cal_sys  = None
    obs      = None

    sig_pdf_splt = None
    sig_pdf_merg = None
    bkg_pdf      = None

    mu       = zfit.Parameter('mu', 3060,  3040, 3100)
    sg       = zfit.Parameter('sg',   20,    10,  100)

    dmu      = zfit.Parameter('dmu', 0, -50.0, 50.0)
    rsg      = zfit.Parameter('rsg', 1, 0.7,  1.4)

    d_sig_ini        =   {}
    d_sig_ini['mu'  ]= 3060
    d_sig_ini['sg'  ]= 20.0
    d_sig_ini['ap_r']=  1.0
    d_sig_ini['pw_r']=  1.0
    d_sig_ini['ap_l']= -1.0
    d_sig_ini['pw_l']=  1.0
    d_sig_ini['ncbr']=  1000 
    d_sig_ini['ncbl']=  1000  
#-------------------
def get_years(dset):
    if   dset == 'r1':
        l_year = ['2011', '2012'] 
    elif dset == 'r2p1':
        l_year = ['2015', '2016'] 
    else:
        l_year = [dset] 

    return l_year
#-------------------
def get_cached_paths(dset, trig, proc):
    l_year    = get_years(dset)
    cache_dir = f'{data.cas_dir}/tools/apply_selection/q2_smear'
    l_path    = []
    for year in l_year:
        wc      = f'{cache_dir}/{proc}/{data.dat_vers}/{year}_{trig}/*.root'
        data.log.info(f'Using files in: {wc}')
        l_path += utnr.glob_wc(wc, allow_empty=False)

    all_found = True 
    for path in l_path:
        if not os.path.isfile(path):
            all_found=False
            break

    return l_path, all_found
#-------------------
def get_input_paths(proc, dset):
    l_year = get_years(dset)

    l_path = [f'{data.dat_dir}/{proc}/{data.dat_vers}/{year}.root' for year in l_year ]
    for path in l_path:
        if not os.path.isfile(path):
            data.log.error(f'File {path} not found')
            raise FileNotFoundError

    return l_path
#-------------------
def get_df(year, trig, brem, identifier, is_data=None):
    if data.sam == 'simulation' and is_data:
        return

    if data.sam == 'data' and not is_data:
        return

    if is_data not in [True, False]:
        data.log.error(f'Dataset type not specified')
        raise

    proc = 'data' if is_data else 'ctrl'
    l_cache_path, all_exist = get_cached_paths(year, trig, proc)
    if not all_exist:
        data.log.error(f'Not found all files')
        raise

    data.log.debug(f'Found cached files: {l_cache_path}:{trig}')
    rdf = ROOT.RDataFrame(trig, l_cache_path)
    rdf = get_range_rdf(rdf)
    check_nopid(rdf, trig, year)

    rdf = apply_selection(rdf, trig, year, brem, proc)
    rdf = add_weights(rdf, trig, year, is_data, identifier)

    return rdf
#-------------------
def get_range_rdf(rdf):
    if data.nentries > 0:
        ntotal = rdf.Count().GetValue()
        data.log.visible(f'Using {data.nentries}/{ntotal} entries')
        rdf = rdf.Range(data.nentries)

    return rdf
#-------------------
def check_nopid(rdf, trig, year):
    '''Checks that PID cut has not been added
    '''
    pid_cut = rs.get('pid', trig, q2bin='none', year=year)

    rdf_org = rdf.Range(1000)
    rdf_cut = rdf.Filter(pid_cut, 'PID')

    norg = rdf_org.Count().GetValue()
    ncut = rdf_cut.Count().GetValue()

    if norg == ncut:
        data.log.error(f'PID cut already applied')
        rep = rdf_cut.Report()
        rep.Print()
        raise
#-------------------
def add_weights(rdf, trig, year, is_data, identifier):
    if is_data:
        pid_cut = rs.get('pid', trig, q2bin='none', year=year)
        rdf     = rdf.Define('weight', pid_cut)
    else:
        rdf     = add_cal_wgt(rdf, trig, year, 'weight', identifier)

    rdf = rdf.Redefine('weight', 'float(weight)')
    wgt = rdf.Sum('weight').GetValue()
    data.log.visible(f'Sum of weights: {wgt}')

    return rdf
#-------------------
def add_cal_wgt(rdf, trig, year, weight, identifier):
    rdf.filepath = 'no-path'
    rdf.treename = trig 
    rdf.trigger  = trig 
    rdf.year     = year

    d_set            = {}
    d_set['val_dir'] = f'{data.plt_dir}/cal_wgt_{identifier}'
    d_set['replica'] = 0
    d_set['bts_ver'] ='10'
    d_set['bts_sys'] ='nom'
    d_set['pid_sys'] = data.cal_sys 
    d_set['trk_sys'] = data.cal_sys 
    d_set['gen_sys'] = data.cal_sys 
    d_set['lzr_sys'] = data.cal_sys 
    d_set['hlt_sys'] = data.cal_sys 
    d_set['rec_sys'] = data.cal_sys 

    obj         = wgt_mgr(d_set)
    obj.log_lvl = logging.WARNING
    rsl         = obj.get_reader('sel', rdf)

    gen_syst, lzr_syst, hlt_syst, rec_syst = get_wgt_syst(trig)

    arr_pid     = rsl('pid', data.cal_sys)
    arr_trk     = rsl('trk', data.cal_sys)
    arr_gen     = rsl('gen', gen_syst)
    arr_lzr     = rsl('lzr', lzr_syst)
    arr_hlt     = rsl('hlt', hlt_syst)
    arr_rec     = rsl('rec', rec_syst)

    arr_cal = arr_pid * arr_trk * arr_gen * arr_lzr * arr_hlt * arr_rec

    rdf = utils.add_df_column(rdf, arr_cal,  weight, d_opt={'exclude_re' : 'tmva_.*'})

    return rdf
#-------------------
def get_wgt_syst(trigger):
    '''Will return systematic for L0 and GEN weights corresponding to _cal_sys [nom, 000]
    '''
    if   data.cal_sys == 'nom':
        gen_syst = 'MTOS'
    elif data.cal_sys == '000':
        gen_syst = '000'
    else:
        data.log.error(f'Invalid systematic: {data.cal_sys}')
        raise

    if   data.cal_sys == '000':
        lzr_syst = '000'
    elif trigger == 'MTOS':
        lzr_syst = 'L0MuonTIS'
    elif trigger == 'ETOS':
        lzr_syst = 'L0ElectronTIS'
    elif trigger == 'GTIS':
        lzr_syst = 'L0TIS_EMMH.L0HadronElEL.L0ElectronTIS'
    else:
        log.error(f'Invalid HLT tag: {trigger}')
        raise

    if   data.cal_sys == 'nom':
        hlt_syst = trigger 
    elif data.cal_sys == '000':
        hlt_syst = '000'
    else:
        log.error(f'Invalid systematic: {data.cal_sys}')
        raise

    return gen_syst, lzr_syst, hlt_syst, hlt_syst
#-------------------
def get_branches(rdf):
    v_col = rdf.GetColumnNames()
    l_col = [ str(col.c_str()) for col in v_col ]

    l_branch = []
    l_branch.append('b_mass')
    l_branch.append('Jpsi_M')
    l_branch.append('nSPDHits')

    l_branch.append('nbrem')
    l_branch.append('L1_HasBremAdded')
    l_branch.append('L2_HasBremAdded')
    
    l_branch.append('L1_P')
    l_branch.append('L2_P')

    if 'Jpsi_TRUEID' in l_col:
        l_branch.append('Jpsi_TRUEID')
        l_branch.append('L1_TRUEID')
        l_branch.append('L2_TRUEID')

    return l_branch
#-------------------
def add_bdt(rdf, trig):
    rdf = rdf.Define('b_mass', data.b_mass)
    rdf = rdf.Define('nbrem' , 'L1_BremMultiplicity + L2_BremMultiplicity')
    rdf = rdf.Redefine('L1_HasBremAdded', 'int(L1_HasBremAdded)')
    rdf = rdf.Redefine('L2_HasBremAdded', 'int(L2_HasBremAdded)')

    l_branch      = get_branches(rdf)
    d_data        = rdf.AsNumpy(l_branch)
    man           = mva_man(rdf, data.bdt_dir, trig)
    d_data['BDT'] = man.get_scores()

    return ROOT.RDF.MakeNumpyDataFrame(d_data)
#-------------------
def apply_selection(rdf, trig, year, brem, proc):
    rdf     = rdf.Define('nbrem', 'L1_BremMultiplicity + L2_BremMultiplicity')
    if brem == 2:
        brm_cut = f'nbrem>=2'
    else:
        brm_cut = f'nbrem=={brem}'

    rdf = rdf.Filter(brm_cut, brm_cut)
    rep = rdf.Report()

    rep.Print()

    return rdf
#-------------------
def float_pars(pdf):
    l_par    = list(pdf.get_params(floating=True)) + list(pdf.get_params(floating=False))
    data.log.info('Floating parameters:')
    for par in l_par:
        par.floating = True
        if par.name in data.d_sig_ini:
            val = data.d_sig_ini[par.name]
            par.set_value(val)

        data.log.info(f'{"":<4}{par.name:<20}{par.value():>20.3f}')
#-------------------
def reset_sig_pars(pdf, d_val):
    l_par    = list(pdf.get_params(floating=True)) + list(pdf.get_params(floating=False))
    data.log.info('Setting initial values:')
    for par in l_par:
        name = par.name
        if name not in d_val:
            continue

        val  = d_val[name]
        par.set_value(val)
        data.log.info(f'{name:<20}{"->":<10}{val:<10.3}')
#-------------------
def get_nspd_signal(l_pdf):
    nsg_1 = zfit.Parameter('nsg_1', 1000, 0, data.nevs_data)
    nsg_2 = zfit.Parameter('nsg_2', 1000, 0, data.nevs_data)
    nsg_3 = zfit.Parameter('nsg_3', 1000, 0, data.nevs_data)

    l_nsg = [nsg_1, nsg_2, nsg_3]
    l_epdf= [ pdf.create_extended(nsg) for pdf, nsg in zip(l_pdf, l_nsg) ]
    epdf  = zfit.pdf.SumPDF(pdfs=l_epdf)

    return epdf
#-------------------
def get_cb_pdf():
    ap_r  = zfit.Parameter('ap_r',  1.0,  -10.0, 10.0)
    pw_r  = zfit.Parameter('pw_r',  1.0,    0.1, 10.0)
    sig_r = zfit.pdf.CrystalBall(obs=data.obs, mu=data.mu, sigma=data.sg, alpha=ap_r, n=pw_r)

    ap_l  = zfit.Parameter('ap_l', -1.0,  -10.0, 10.0)
    pw_l  = zfit.Parameter('pw_l',  1.0,    0.1,  10.)
    sig_l = zfit.pdf.CrystalBall(obs=data.obs, mu=data.mu, sigma=data.sg, alpha=ap_l, n=pw_l)

    ncbr  = zfit.Parameter('ncbr',  10,   0,  1000000)
    sig_r = sig_r.create_extended(ncbr, name='CB1')

    ncbl  = zfit.Parameter('ncbl',  10,   0,  1000000)
    sig_l = sig_l.create_extended(ncbl, name='CB2') 

    sig   = zfit.pdf.SumPDF([sig_r, sig_l], name='Signal')

    return sig
#-------------------
def get_nspd_data_pars(preffix=''):
    sim_mu = zfit.param.ConstantParameter(f'sim_mu{preffix}', data.d_sim_par[f'mu{preffix}'][0])
    sim_sg = zfit.param.ConstantParameter(f'sim_sg{preffix}', data.d_sim_par[f'sg{preffix}'][0])

    dat_mu = zfit.ComposedParameter(f'dat_mu{preffix}', 
                                    lambda d_par : d_par['dmu'] + d_par[f'sim_mu{preffix}'], 
                                    {'dmu' : data.dmu, f'sim_mu{preffix}' : sim_mu} )
    dat_sg = zfit.ComposedParameter(f'dat_sg{preffix}', 
                                    lambda d_par : d_par['rsg'] * d_par[f'sim_sg{preffix}'], 
                                    {'rsg' : data.rsg, f'sim_sg{preffix}' : sim_sg} )

    return dat_mu, dat_sg
#-------------------
def get_cb_nspd_pdf(prefix=''):
    mu,sg = get_nspd_data_pars(prefix)

    ap_r  = zfit.Parameter(f'ap_r{prefix}',  1.0,  -10.0, 10.0)
    pw_r  = zfit.Parameter(f'pw_r{prefix}',  1.0,    0.1, 10.0)
    sig_r = zfit.pdf.CrystalBall(obs=data.obs, mu=mu, sigma=sg, alpha=ap_r, n=pw_r)

    ap_l  = zfit.Parameter(f'ap_l{prefix}', -1.0,  -10.0, 10.0)
    pw_l  = zfit.Parameter(f'pw_l{prefix}',  1.0,    0.1,  10.)
    sig_l = zfit.pdf.CrystalBall(obs=data.obs, mu=mu, sigma=sg, alpha=ap_l, n=pw_l)

    fr    = zfit.Parameter(f'fr_cb{prefix}', 0.5,  0.0, 1)
    sig   = zfit.pdf.SumPDF([sig_r, sig_l], fracs=[fr])

    return sig
#-------------------
def get_signal_pdf(split_by_nspd = False, prefix=None):
    if   data.sig_pdf_splt is not None and     split_by_nspd:
        return data.sig_pdf_splt
    elif data.sig_pdf_merg is not None and not split_by_nspd:
        return data.sig_pdf_merg

    if split_by_nspd:
        l_pdf = [ get_cb_nspd_pdf(prefix=f'_{i_nspd}') for i_nspd in [1, 2, 3] ]
        data.sig_pdf_splt = get_nspd_signal(l_pdf)
    else:
        data.sig_pdf_merg = get_cb_pdf()

    return data.sig_pdf_splt if split_by_nspd else data.sig_pdf_merg 
#-------------------
def get_bkg_pdf():
    if data.bkg_pdf is not None:
        return data.bkg_pdf

    lam = zfit.Parameter('lam', -0.001, -0.1, -0.0001)
    bkg = zfit.pdf.Exponential(lam=lam, obs=data.obs, name='')

    nbk = zfit.Parameter(f'nbk', 100, 0.0, 200000)
    bkg = bkg.create_extended(nbk, name='Combinatorial')

    data.bkg_pdf = bkg

    return bkg
#-------------------
def get_full_pdf(split_by_nspd): 
    sig = get_signal_pdf(split_by_nspd)
    bkg = get_bkg_pdf()
    pdf = zfit.pdf.SumPDF([sig, bkg], name='Model')

    data.log.debug(f'Signal    : {sig}')
    data.log.debug(f'Background: {bkg}')
    data.log.debug(f'Model     : {pdf}')

    return pdf
#-------------------
def fix_pdf(pdf, d_fix):
    if d_fix is None:
        return pdf

    l_par = list(pdf.get_params(floating=True))

    data.log.info('-----------------')
    data.log.info('Fixing parameters')
    data.log.info('-----------------')
    for par in l_par:
        if re.match(r'mu_[1,2,3]', par.name) or re.match(r'sg_[1,2,3]', par.name):
            continue

        if par.name not in d_fix:
            data.log.visible(f'{par.name:<20}{"->":<10}{"floating":>20}')
            continue
        else:
            fix_val, _ = d_fix[par.name]

        par.assign(fix_val)
        par.floating=False

        data.log.info(f'{par.name:<20}{"->":<10}{fix_val:>20.3e}')

    return pdf
#-------------------
def get_pdf(is_signal=None, split_by_nspd=None):
    if is_signal     not in [True, False]:
        data.log.error('Signal flag not specified')
        raise

    if split_by_nspd not in [True, False]:
        data.log.error('split_by_nspd flag not specified')
        raise

    pdf = get_signal_pdf() if is_signal else get_full_pdf(split_by_nspd)

    return pdf
#-------------------
def fit(df, d_fix=None, identifier='unnamed'):
    jsn_path  = f'{data.plt_dir}/{identifier}.json'
    if os.path.isfile(jsn_path):
        data.log.info(f'Fit file found: {jsn_path}')
        d_par = utnr.load_json(jsn_path)
        return d_par

    is_signal = True if d_fix is None else False

    if   identifier.endswith('_nspd'):
        data.log.info(f'Splitting by nSPD: {identifier}')
        pdf = get_pdf(is_signal, split_by_nspd= True)
    elif identifier.endswith( '_nom'):
        data.log.info(f'Not splitting by nSPD: {identifier}')
        pdf = get_pdf(is_signal, split_by_nspd=False)
    else:
        data.log.error(f'Invalid identifier: {identifier}')
        raise

    if is_signal:
        float_pars(pdf)
        if os.path.isfile(jsn_path):
            data.log.info(f'Loading cached simulation parameters: {jsn_path}')
            d_par = utnr.load_json(jsn_path)
            reset_sig_pars(pdf, d_par)

    dat = get_data(df, pdf, is_signal, identifier)
    pdf = fix_pdf(pdf, d_fix)
    obj = zfitter(pdf, dat)

    if   data.skip_fit:
        log.info('Skipping fit')
        res=None
    elif is_signal:
        res=obj.fit(ntries=10, pval_threshold=0.04)
    else:
        res=obj.fit()

    plot_fit(dat, pdf, res, identifier, add_pars=None)

    if   data.skip_fit:
        return
    elif res is None:
        plot_fit(dat, pdf, res, identifier, add_pars=None)
        plot_fit(dat, pdf, res, identifier, add_pars='all')

        data.log.error(f'Fit failed')
        print(res)
        raise
    elif res.status != 0:
        plot_fit(dat, pdf, res, identifier, add_pars=None)
        plot_fit(dat, pdf, res, identifier, add_pars='all')

        data.log.error(f'Finished with status/validity: {res.status}/{res.valid}')
        print(res)
        raise
    else:
        with zfit.run.set_autograd_mode(False):
            res.hesse(method='minuit_hesse')
        res.freeze()
        print(res)

    plot_fit(dat, pdf, res, identifier, add_pars='all')

    tex_path = f'{data.plt_dir}/{identifier}.tex'
    data.log.visible(f'Saving to: {tex_path}')
    result_to_latex(res, tex_path, method='minos')

    pkl_path = f'{data.plt_dir}/{identifier}.pkl'
    utnr.dump_pickle(res, pkl_path)

    d_par = { name : [ d_val['value'], d_val['hesse']['error'] ] for name, d_val in res.params.items() }

    utnr.dump_json(d_par, jsn_path)

    return d_par
#-------------------
def get_data(rdf, pdf, is_signal, identifier):
    arr_val = rdf.AsNumpy(['Jpsi_M'])['Jpsi_M']
    arr_wgt = rdf.AsNumpy(['weight'])['weight']

    obs     = pdf.space
    dat     = zfit.Data.from_numpy(obs=obs, array=arr_val, weights=arr_wgt)

    plot_data(arr_val, arr_wgt, obs, is_signal, identifier)

    return dat
#-------------------
def get_obs_range():
    if data.brem == '0':
        return [2200, 3300]
    else:
        return [2200, 3800]
#-------------------
def plot_data(arr_mas, arr_wgt, obs, is_signal, identifier):
    plt.close('all')
    [[lower]], [[upper]] = obs.limits

    fig, ax   = plt.subplots(figsize=(15, 10))
    data_hist = hist.Hist.new.Regular(data.nbins, lower, upper, name='', underflow=False, overflow=False)
    data_hist = data_hist.Weight()
    data_hist.fill(arr_mas, weight=arr_wgt)

    errorbars = mplhep.histplot(
        data_hist,
        yerr    = True,
        color   = 'black',
        histtype= 'errorbar',
        ax      = ax
    )

    title=f'Entries={arr_wgt.size:.0f}; Sum={numpy.sum(arr_wgt):.0f}; {identifier}'

    if is_signal:
        plt_path = f'{data.plt_dir}/ctrl_{identifier}.png'
    else:
        plt_path = f'{data.plt_dir}/data_{identifier}.png'

    data.log.visible(f'Saving to: {plt_path}')
    plt.title(title)
    plt.savefig(plt_path)
    plt.close('all')
#-------------------
def plot_fit(dat, pdf, res, identifier, add_pars=None):
    obj=zfp(data=dat, model=pdf, result=res)
    obj.plot(nbins=data.nbins, d_leg={}, plot_range=get_obs_range(), ext_text=f'#events={dat.nevents.numpy()}', add_pars=add_pars)
    obj.axs[1].plot(get_obs_range(), [0, 0], linestyle='--', color='black')

    if add_pars is not None:
        plot_path = f'{data.plt_dir}/{identifier}_pars.png'
    else:
        plot_path = f'{data.plt_dir}/{identifier}.png'

    data.log.visible(f'Saving to: {plot_path}')
    plt.savefig(plot_path, bbox_inches='tight')
#-------------------
def get_fix_pars(d_par):
    d_fix = dict(d_par)
    for parname in d_par: 
        if parname.startswith('mu') or parname.startswith('sg'):
            del(d_fix[parname])

    if data.sys == 'nspd':
        for index in [1,2,3]:
            ryld = d_fix[f'ncbr_{index}'][0]
            lyld = d_fix[f'ncbl_{index}'][0]
            d_fix[f'fr_cb_{index}'] = [ryld / (ryld + lyld), 0]

            del(d_fix[f'ncbr_{index}'])
            del(d_fix[f'ncbl_{index}'])
    else:
        del(d_fix['ncbr'])
        del(d_fix['ncbl'])

    return d_fix
#-------------------
def add_nspd_col(df):
    arr_nspd = df.AsNumpy(['nSPDHits'])['nSPDHits']
    q1 = numpy.quantile(arr_nspd, 1./3)
    q2 = numpy.quantile(arr_nspd, 2./3)

    df = df.Define('nspd', f'float res=-1; if (nSPDHits<{q1}) res = 1; else if (nSPDHits < {q2}) res = 2; else res = 3; return res;')

    return df
#-------------------
def get_sim_pars_cache(trig=None, year=None, brem=None):
    json_wc = f'{data.plt_dir}/sim_{trig}_{year}_{brem}*.json'
    l_json_path = glob.glob(json_wc)
    if len(l_json_path) == 0:
        data.log.error(f'No file found in: {json_wc}')
        raise
    elif len(l_json_path) == 1:
        d_par = utnr.load_json(l_json_path[0])
    else:
        d_par = {}
        for i_nspd, json_path in enumerate(l_json_path):
            data.log.info(f'Loading parameters from: {json_path}')
            d_par_x = utnr.load_json(json_path)
            d_par_r = {f'{key}_{i_nspd + 1}' : val for key, val in d_par_x.items()}
            d_par.update(d_par_r)

    return d_par
#-------------------
def get_sim_pars_fits(df, identifier):
    d_par = {}
    if   data.sys == 'nspd':
        df = add_nspd_col(df)
        for i_nspd in [1,2,3]:
            df_sim_nspd = df.Filter(f'nspd == {i_nspd}')
            d_tmp_1     = fit(df_sim_nspd, d_fix=None, identifier=f'sim_{identifier}_{i_nspd}')
            d_tmp_2     = { f'{key}_{i_nspd}' : val for key, val in d_tmp_1.items() }
            d_par.update(d_tmp_2)
    elif data.sys == 'nom':
        d_par = fit(df, d_fix=None, identifier=f'sim_{identifier}')
    else:
        data.log.error(f'Invalid systematic: {data.sys}')
        raise
    
    return d_par
#-------------------
def make_table(trig=None, year=None, brem=None):
    identifier= f'{trig}_{year}_{brem}_{data.sys}'
    df_sim    = get_df(year, trig, brem, f'sim_{identifier}', is_data=False)
    df_dat    = get_df(year, trig, brem, f'dat_{identifier}', is_data= True)

    if data.sam == 'data':
        d_sim_par = get_sim_pars_cache(trig, year, brem)
    else:
        d_sim_par = get_sim_pars_fits(df_sim, identifier)

    if data.sam == 'simulation':
        data.log.info(f'Done with simulation and returning')
        return

    data.d_sim_par = d_sim_par
    data.nevs_data = df_dat.Count().GetValue()

    d_fix_par = get_fix_pars(d_sim_par)
    _         = fit(df_dat, d_fix=d_fix_par, identifier=f'dat_{trig}_{year}_{brem}_{data.sys}')
#-------------------
def get_args():
    parser = argparse.ArgumentParser(description='Used to produce q2 smearing factors systematic tables')
    parser.add_argument('-v', '--vers' , type =str, help='Version, used for naming of output directory', required=True)
    parser.add_argument('-t', '--trig' , type =str, help='Trigger'                                     , required=True, choices=data.l_trig)
    parser.add_argument('-y', '--year' , type =str, help='Year'                                        , required=True, choices=data.l_year)
    parser.add_argument('-b', '--brem' , type =str, help='Brem category'                               , required=True, choices=data.l_brem)
    parser.add_argument('-c', '--cali' , type =str, help='Calibration weight systematics'              , default='nom', choices=data.l_cali)
    parser.add_argument('-x', '--sys'  , type =str, help='Systematic variabion'                        , choices=data.l_sys) 
    parser.add_argument('-s', '--sam'  , type =str, help='Sample'                                      , choices=data.l_sam, default='both') 
    parser.add_argument('-e', '--nent' , type =int, help='Number of entries to run over, for tests'    , default=-1) 
    parser.add_argument('--skip_fit'   , help='Will not fit, just plot the model'                      , action='store_true') 
    args = parser.parse_args()

    data.trig     = args.trig
    data.year     = args.year
    data.brem     = args.brem
    data.sys      = args.sys
    data.sam      = args.sam
    data.cal_sys  = args.cali
    data.nentries = args.nent
    data.skip_fit = args.skip_fit

    syst          = {'nom' : 'nom', 'nspd' : 'lsh'}[data.sys]
    data.plt_dir  = utnr.make_dir_path(f'{data.qsq_dir}/get_q2_tables/fits/{args.vers}.{syst}')
    data.obs      = zfit.Space('Jpsi_M', limits=get_obs_range())
#-------------------
def main():
    plt.style.use(mplhep.style.LHCb2)

    get_args()
    make_table(trig=data.trig, year=data.year, brem=data.brem)
#-------------------
if __name__ == '__main__':
    main()

